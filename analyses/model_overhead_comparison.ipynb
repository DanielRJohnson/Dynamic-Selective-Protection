{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"running_all\" not in globals():\n",
    "    from ipywidgets import widgets\n",
    "    matrices = [\"ex10\", \"msc04515\", \"s1rmq4m1\", \"Na5\", \"bcsstk18\",\n",
    "                \"vibrobox\", \"cbuckle\", \"Pres_Poisson\", \"raefsky4\", \"vanbody\",\n",
    "                \"ct20stif\", \"cant\", \"bcircuit\", \"apache1\", \"consph\"]\n",
    "    b = widgets.Button(description=\"Run over all matrices\", button_style=\"success\")\n",
    "    output = widgets.Output()\n",
    "\n",
    "    display(b, output)\n",
    "\n",
    "    def run_over_all_matrices(button):\n",
    "        global running_all\n",
    "        global matrix\n",
    "        running_all = True\n",
    "        with output:\n",
    "            for matrix in matrices:\n",
    "                print(f\"Running {matrix}...\")\n",
    "                %run ./model_overhead_comparison.ipynb # will output at this cell rather than later\n",
    "            print(\"Finished!\")\n",
    "    b.on_click(run_over_all_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"running_all\" not in globals():\n",
    "    matrix = \"bcsstk18\"  # manually set to run over one matrix\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "from joblib import load\n",
    "from json import load as json_load\n",
    "from glob import glob\n",
    "sys.path.append(os.path.join(os.getcwd(), os.pardir))\n",
    "from io_utils import load_matrices_from_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data_size(name):\n",
    "    if name in [\"vanbody\", \"cant\"]:\n",
    "        return 100\n",
    "    return 1000\n",
    "\n",
    "\n",
    "ylims = {\n",
    "    \"apache1\": (0, 0.25),\n",
    "    \"bcircuit\": (0, 0.8),\n",
    "    \"bcsstk18\": (0.2, 1.5),\n",
    "    \"cant\": (0.6, 1.3),\n",
    "    \"cbuckle\": (0, 1.0),\n",
    "    \"consph\": (0, 0.02),\n",
    "    \"ct20stif\": (0, 1.5),\n",
    "    \"ex10\": (0.4, 1.5),\n",
    "    \"msc04515\": (0, 0.4),\n",
    "    \"Na5\": (0, 0.6),\n",
    "    \"Pres_Poisson\": (0, 0.5),\n",
    "    \"raefsky4\": (0, 0.2),\n",
    "    \"s1rmq4m1\": (0, 0.6),\n",
    "    \"vanbody\": (0.9, 1.05),\n",
    "    \"vibrobox\": (0.2, 1.2),\n",
    "}\n",
    "\n",
    "df = pd.read_csv(f\"data/{matrix}_{get_test_data_size(matrix)}.csv\")\n",
    "errorfree_iterations = df[\"errorfree_iterations\"][0]  # all the same\n",
    "n_rows = df[\"n_rows\"][0]  # all the same\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_names = {\n",
    "    \"Ridge\": \"Polynomial Regression\",\n",
    "    \"RandomForestRegressor\": \"Random Forest\",\n",
    "    \"KNeighborsRegressor\": \"K-Nearest Neighbors\",\n",
    "    \"XGBRegressor\": \"XGBoost\",\n",
    "    \"LinearSVR\": \"Support Vector Machine\"\n",
    "}\n",
    "\n",
    "models = [load(fn) for fn in glob(f\"./models/{matrix}/*.pkl\")]\n",
    "model_names = [real_names[model.steps[-1][1].__class__.__name__] for model in models]\n",
    "ps = [1/98] + list(np.arange(0.02, 1.01, 0.01))\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"error_iter\", \"pos_2norm\"]].to_numpy()\n",
    "\n",
    "for name, model in zip(model_names, models):\n",
    "    df[f\"prot_score_{name}\"] = model.predict(X)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mats = load_matrices_from_dir(\"../matrices/raw\", subset=[matrix])\n",
    "mat = list(mats.values())[0]\n",
    "\n",
    "with open(f\"../matrices/2norms/{matrix}_pos_2norms.json\") as f:\n",
    "    pos_2norms = json_load(f)\n",
    "\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame([[i, pos_2norms[str(pos)], pos] for pos in range(mat.shape[0])\n",
    "                         for i in range(errorfree_iterations)], columns=[\"i\", \"2norm\", \"rowid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in zip(model_names, models):\n",
    "    df_preds[f\"output_{name}\"] = model.predict(df_preds[[\"i\", \"2norm\"]])\n",
    "df_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = [1/98] + list(np.arange(0.02, 1.01, 0.01))\n",
    "percentages = np.arange(0.01, 1.0, 0.01)\n",
    "nonerror_runs_by_p = {p: int((len(df) / p) - len(df)) for p in ps}\n",
    "max_nonerror_runs = int((len(df) / min(ps)) - len(df))\n",
    "solve_iterations = np.append(df[\"solve_iterations\"], [errorfree_iterations] * max_nonerror_runs)\n",
    "slowdowns = np.append(df[\"slowdown\"], [1] * max_nonerror_runs)\n",
    "errorfree_op_count = errorfree_iterations * n_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_overheads(error_iterations, n_protections):\n",
    "    return ((error_iterations * n_rows + n_protections) - errorfree_op_count) / errorfree_op_count\n",
    "\n",
    "\n",
    "def protect(error_iterations, protections):\n",
    "    return np.vectorize(lambda i: error_iterations[i] if not protections[i]\n",
    "                        else errorfree_iterations)(range(len(error_iterations)))\n",
    "\n",
    "\n",
    "def make_p_overhead_dataframe(ohs_by_p):\n",
    "    return pd.concat([pd.DataFrame({\"p\": [ps[i]] * len(os), \"overhead\": os})\n",
    "                      for i, os in enumerate(ohs_by_p)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "\n",
    "for name, model in zip(model_names, models):\n",
    "    prot_overheads_by_p = []\n",
    "\n",
    "    for p in ps:\n",
    "        # need to pad dataset to add non-error runs\n",
    "        n_nonerror_runs = nonerror_runs_by_p[p]\n",
    "        data_size = n_nonerror_runs + len(df)\n",
    "\n",
    "        # for the purpose of choosing solve_iterations or errorfree_iterations, did_protect will\n",
    "        # always be False for nonerror runs, but this is fine because n_protections is computed\n",
    "        # later for the purposes of calculating overhead\n",
    "        protections = np.append(df[f\"prot_score_{name}\"] > (1 + (1 / p)), [False] * n_nonerror_runs)\n",
    "\n",
    "        prot_iterations = protect(solve_iterations[:data_size], protections)\n",
    "        n_protections = (df_preds[f\"output_{name}\"] > (1 + (1 / p))).sum()\n",
    "\n",
    "        prot_overheads = compute_overheads(prot_iterations, n_protections)\n",
    "        prot_overheads_by_p.append(prot_overheads)\n",
    "\n",
    "    dfs[name] = make_p_overhead_dataframe(prot_overheads_by_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette(\"tab10\", 6)[1:]\n",
    "for i, (name, model_df) in enumerate(dfs.items()):\n",
    "    sns.lineplot(model_df, x=\"p\", y=\"overhead\", c=palette[i], label=name)\n",
    "\n",
    "\n",
    "def formatter(x, pos):\n",
    "    del pos\n",
    "    return str(round(x * 100))\n",
    "\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(formatter)\n",
    "plt.gcf().set_size_inches(8, 6)\n",
    "plt.gcf().set_dpi(100)\n",
    "\n",
    "plt.xlabel(\"$p$\")\n",
    "plt.ylabel(\"Mean Overhead (%)\")\n",
    "plt.title(f\"{matrix}\", weight=\"bold\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlim(0.01, 1)\n",
    "plt.ylim(*ylims[matrix])\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"./figures/{matrix}/model_overhead_comparison.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
